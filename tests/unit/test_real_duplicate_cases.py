#!/usr/bin/env python3
"""
å®Ÿéš›ã®test_video.ja.srtã®é‡è¤‡ã‚±ãƒ¼ã‚¹ã‚’ä½¿ã£ãŸãƒ†ã‚¹ãƒˆï¼ˆassertæ–‡ç‰ˆï¼‰
"""

import sys
from dataclasses import dataclass
from pathlib import Path
from typing import List, Optional, Tuple

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent.parent))


@dataclass
class MockSubtitleItem:
    """SubtitleItem ã®ãƒ¢ãƒƒã‚¯"""

    index: int
    start_ms: int
    end_ms: int
    text: str
    bbox: Optional[Tuple[int, int, int, int]] = None


class MockTextSimilarityCalculator:
    """TextSimilarityCalculator ã®ãƒ¢ãƒƒã‚¯"""

    @staticmethod
    def calculate_similarity(text1: str, text2: str) -> float:
        """ç°¡å˜ãªé¡ä¼¼åº¦è¨ˆç®—"""
        if not text1 or not text2:
            return 0.0

        if text1 == text2:
            return 1.0

        # æ­£è¦åŒ–
        norm_text1 = text1.lower().replace(" ", "").replace("ã€", "").replace("ã€‚", "")
        norm_text2 = text2.lower().replace(" ", "").replace("ã€", "").replace("ã€‚", "")

        if norm_text1 == norm_text2:
            return 1.0

        # OCRèª¤èªè­˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è£œæ­£
        corrections = {"ã‚·ãƒ¤": "ã‚·ãƒ£", "ãƒ­": "å£", "å£": "ãƒ­"}

        for wrong, correct in corrections.items():
            norm_text1 = norm_text1.replace(wrong, correct)
            norm_text2 = norm_text2.replace(wrong, correct)

        if norm_text1 == norm_text2:
            return 1.0

        # é•·ã•æ¯”
        len_ratio = min(len(norm_text1), len(norm_text2)) / max(
            len(norm_text1), len(norm_text2)
        )
        if len_ratio < 0.8:
            return 0.0

        # ä½ç½®ä¸€è‡´ã®é¡ä¼¼åº¦
        min_len = min(len(norm_text1), len(norm_text2))
        common_chars = sum(1 for i in range(min_len) if norm_text1[i] == norm_text2[i])
        max_len = max(len(norm_text1), len(norm_text2))

        return common_chars / max_len


def merge_time_constrained_duplicates(
    subtitles: List[MockSubtitleItem],
) -> List[MockSubtitleItem]:
    """æ™‚é–“åˆ¶ç´„ä»˜ãã®é‡è¤‡çµ±åˆãƒ­ã‚¸ãƒƒã‚¯"""
    if not subtitles:
        return []

    merged = []
    calc = MockTextSimilarityCalculator()
    max_merge_gap_ms = 30000  # 30ç§’ä»¥å†…ã®å­—å¹•ã®ã¿çµ±åˆå¯¾è±¡

    subtitles_copy = subtitles.copy()
    i = 0
    while i < len(subtitles_copy):
        current_group = [subtitles_copy[i]]
        j = i + 1

        # ç¾åœ¨ã®å­—å¹•ã‹ã‚‰30ç§’ä»¥å†…ã®é¡ä¼¼å­—å¹•ã‚’æ¢ã™
        while j < len(subtitles_copy):
            time_gap = subtitles_copy[j].start_ms - subtitles_copy[i].end_ms

            # æ™‚é–“é–“éš”ãŒ30ç§’ã‚’è¶…ãˆãŸã‚‰çµ±åˆå¯¾è±¡å¤–
            if time_gap > max_merge_gap_ms:
                break

            # ãƒ†ã‚­ã‚¹ãƒˆé¡ä¼¼åº¦ãƒã‚§ãƒƒã‚¯
            similarity = calc.calculate_similarity(
                subtitles_copy[i].text, subtitles_copy[j].text
            )

            if similarity > 0.90:
                current_group.append(subtitles_copy[j])
                subtitles_copy.pop(j)
            else:
                j += 1

        # ã‚°ãƒ«ãƒ¼ãƒ—ã‚’çµ±åˆã—ã¦è¿½åŠ 
        if len(current_group) == 1:
            merged.append(current_group[0])
        else:
            merged_subtitle = merge_duplicate_group(current_group)
            merged.append(merged_subtitle)

        i += 1

    return merged


def merge_duplicate_group(group: List[MockSubtitleItem]) -> MockSubtitleItem:
    """åŒã˜ãƒ†ã‚­ã‚¹ãƒˆã®å­—å¹•ã‚°ãƒ«ãƒ¼ãƒ—ã‚’çµ±åˆ"""
    if not group:
        return None

    min_start_ms = min(subtitle.start_ms for subtitle in group)
    max_end_ms = max(subtitle.end_ms for subtitle in group)
    base_subtitle = group[0]

    merged_subtitle = MockSubtitleItem(
        index=base_subtitle.index,
        start_ms=min_start_ms,
        end_ms=max_end_ms,
        text=base_subtitle.text,
        bbox=base_subtitle.bbox,
    )

    return merged_subtitle


def test_real_duplicate_cases():
    """å®Ÿéš›ã®test_video.ja.srtã®é‡è¤‡ã‚±ãƒ¼ã‚¹ã‚’ãƒ†ã‚¹ãƒˆï¼ˆassertæ–‡ä½¿ç”¨ç‰ˆï¼‰"""
    print("=== å®Ÿéš›ã®é‡è¤‡ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ ===")

    # test_video.ja.srtã®å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿
    subtitles = [
        MockSubtitleItem(
            index=1,
            start_ms=0,
            end_ms=1200,
            text="ã•ã¦å›³æ›¸é¤¨è¡Œã£ã¦ã€ç—…é™¢è¡Œã£ã¦ã€ éŠ€è¡Œã«ã‚‚è¡Œã£ã¦ãã‚‹ã§ã¯å‡ºç™ºã§ã™",
        ),
        MockSubtitleItem(
            index=2,
            start_ms=2000,
            end_ms=11200,
            text="ã•ã¦å›³æ›¸é¤¨è¡Œã£ã¦ã€ç—…é™¢è¡Œã£ã¦ã€éŠ€è¡Œã«ã‚‚è¡Œã£ã¦ãã‚‹ã§ã¯å‡ºç™ºã§ã™",
        ),
        MockSubtitleItem(
            index=3,
            start_ms=16000,
            end_ms=27200,
            text="æ±—ã ãã§å¸°å®…ã—ã¾ã—ãŸã€ã‚·ãƒ£ãƒ¯ãƒ¼æµ´ã³ã¦ããŸã®ã§ã‚¹ãƒƒã‚­ãƒªå‡ã‚‰ã›ãŸæ°´æŒã£ã¦å‡ºã‹ã‘ãŸã‘ã©çœŸå¤ã®å¤–å‡ºã¯å±é™ºã ã¨æ€ã£ãŸ",
        ),
        MockSubtitleItem(
            index=4,
            start_ms=22000,
            end_ms=25200,
            text="æ±—ã ãã§å¸°å®…ã—ã¾ã—ãŸã€ã‚·ãƒ¤ãƒ¯ãƒ¼æµ´ã³ã¦ããŸã®ã§ã‚¹ãƒƒã‚­ãƒªå‡ã‚‰ã›ãŸæ°´æŒã£ã¦å‡ºã‹ã‘ãŸã‘ã©çœŸå¤ã®å¤–å‡ºã¯å±é™ºã ã¨æ€ã£ãŸ",
        ),
        MockSubtitleItem(
            index=5,
            start_ms=30000,
            end_ms=39200,
            text="ãŒã‚“æ¤œè¨ºã®æ¤œæŸ»çµæœã¯ç•°å¸¸ãªã—ã§ã—ãŸã“ã‚Œã‹ã‚‰ã‚‚å¹´1ãƒšä¸€ã‚¹ã§å—ã‘ãŸã„ã§ã™",
        ),
        MockSubtitleItem(
            index=6,
            start_ms=42000,
            end_ms=53200,
            text="ãŠæ˜¼ã”ã¯ã‚“ã¯ã‚«ãƒ¬ãƒ¼è•éº¦ã¨ãƒã‚®ãƒˆãƒ­å·»ãã«ã—ã¾ã™åˆå¾Œã«ã¯ã¾ãŸå¤§é‡ã®ãƒã‚®ãƒˆãƒ­ãŒå±Šãã‚‰ã—ã„ã®ã§æ¶ˆåŒ–ã—ã¦ã„ã‹ãªã„ã¨",
        ),
        MockSubtitleItem(
            index=7,
            start_ms=44000,
            end_ms=45200,
            text="ãŠæ˜¼ã”ã¯ã‚“ã¯ã‚«ãƒ¬ãƒ¼è•éº¦ã¨ãƒã‚®ãƒˆãƒ­å·»ãã«ã—ã¾ã™åˆå¾Œã«ã¯ã¾ãŸå¤§é‡ã®ãƒã‚®ãƒˆå£ãŒå±Šãã‚‰ã—ã„ã®ã§æ¶ˆåŒ–ã—ã¦ã„ã‹ãªã„ã¨",
        ),
        MockSubtitleItem(
            index=8,
            start_ms=60000,
            end_ms=65200,
            text="ãªã‚“ã‹ã‚¹ãƒ‘ãƒƒã¨åˆ‡ã‚Œãªãã¦ãƒœãƒ­ãƒœãƒ­ã«ãªã£ã¦ã„ã",
        ),
        MockSubtitleItem(
            index=9,
            start_ms=70000,
            end_ms=71200,
            text="æ˜¨æ—¥ä½œã£ãŸåŠ›ãƒ¬ãƒ¼ãŒå¾®å¦™ã«æ®‹ã£ã¦ãŸã®ã§å‡ºæ±ã§ä¼¸ã°ã—ã¦ã„ãã¾ã™",
        ),
    ]

    print(f"å…ƒã®å­—å¹•æ•°: {len(subtitles)}")

    # æ–°ã—ã„çµ±åˆãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè¡Œ
    merged_subtitles = merge_time_constrained_duplicates(subtitles)

    print(f"çµ±åˆå¾Œå­—å¹•æ•°: {len(merged_subtitles)}")
    print("\nçµ±åˆçµæœ:")

    for subtitle in merged_subtitles:
        print(f"å­—å¹• {subtitle.index}: {subtitle.start_ms}-{subtitle.end_ms}ms")
        print(f"  ãƒ†ã‚­ã‚¹ãƒˆ: {subtitle.text[:50]}...")

    # assertæ–‡ã§æœŸå¾…å€¤ã®ç¢ºèª
    # é‡è¤‡ãŒã‚ã£ãŸ1+2, 3+4, 6+7ã®3çµ„ãŒçµ±åˆã•ã‚Œã¦6å­—å¹•ã«ãªã‚‹ã“ã¨ã‚’æœŸå¾…
    expected_count = 6
    assert (
        len(merged_subtitles) == expected_count
    ), f"æœŸå¾…å€¤ {expected_count} != å®Ÿéš› {len(merged_subtitles)}"
    print(f"\nâœ… ãƒ†ã‚¹ãƒˆæˆåŠŸ: {expected_count}å­—å¹•ã«çµ±åˆã•ã‚Œã¾ã—ãŸ")

    # é‡è¤‡çµ±åˆã®ç¢ºèª
    # 1. å›³æ›¸é¤¨é–¢é€£ãŒçµ±åˆã•ã‚Œã¦ã„ã‚‹ã‹
    library_found = any("å›³æ›¸é¤¨" in s.text for s in merged_subtitles)
    # 2. ã‚·ãƒ£ãƒ¯ãƒ¼é–¢é€£ãŒçµ±åˆã•ã‚Œã¦ã„ã‚‹ã‹
    shower_found = any(
        "ã‚·ãƒ£ãƒ¯ãƒ¼" in s.text or "ã‚·ãƒ¤ãƒ¯ãƒ¼" in s.text for s in merged_subtitles
    )
    # 3. ã‚«ãƒ¬ãƒ¼è•éº¦é–¢é€£ãŒçµ±åˆã•ã‚Œã¦ã„ã‚‹ã‹
    curry_found = any("ã‚«ãƒ¬ãƒ¼è•éº¦" in s.text for s in merged_subtitles)

    assert library_found, "å›³æ›¸é¤¨é–¢é€£ã®å­—å¹•ãŒçµ±åˆã•ã‚Œã¦ã„ã¾ã›ã‚“"
    assert shower_found, "ã‚·ãƒ£ãƒ¯ãƒ¼é–¢é€£ã®å­—å¹•ãŒçµ±åˆã•ã‚Œã¦ã„ã¾ã›ã‚“"
    assert curry_found, "ã‚«ãƒ¬ãƒ¼è•éº¦é–¢é€£ã®å­—å¹•ãŒçµ±åˆã•ã‚Œã¦ã„ã¾ã›ã‚“"
    print("âœ… å…¨ã¦ã®é‡è¤‡å­—å¹•ãŒæ­£ã—ãçµ±åˆã•ã‚Œã¾ã—ãŸ")
    return True


if __name__ == "__main__":
    print("å®Ÿéš›ã®é‡è¤‡ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆé–‹å§‹...\n")

    try:
        if test_real_duplicate_cases():
            print("\nğŸ‰ ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
    except AssertionError as e:
        print(f"\nâŒ ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ: {e}")
        raise  # pytestã®ãŸã‚ã«å†ç™ºç”Ÿ
